{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv does not exist: '../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a1cb7cdfd04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create aiport dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv does not exist: '../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv'"
     ]
    }
   ],
   "source": [
    "import gmaps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats as st\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "# # Google developer API key\n",
    "from config import gkey\n",
    "\n",
    "# # Configure gmaps\n",
    "# gmaps.configure(api_key=gkey)\n",
    "\n",
    "# Create aiport dataframe\n",
    "\n",
    "path = pd.read_csv('../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V2_CSV.csv')\n",
    "df = pd.DataFrame(path)\n",
    "df\n",
    "# airport_df = pd.read_csv('../Resources/Airport_Output.csv')\n",
    "df.fillna(0) \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleaned = df.drop(columns=df.columns[(df['No_of_Skills'] == '0').any()])\n",
    "df_cleaned = df.dropna(subset=['No_of_Skills'])\n",
    "df_cleaned['No_of_Skills'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats summary\n",
    "average=df_cleaned.groupby(['Job_Type']).mean()['Salary_Index']\n",
    "median=df_cleaned.groupby(['Job_Type']).median()['Salary_Index']\n",
    "variance=df_cleaned.groupby(['Job_Type']).var()['Salary_Index']\n",
    "standard_deviation=df_cleaned.groupby(['Job_Type']).std()['Salary_Index']\n",
    "sem=df_cleaned.groupby(['Job_Type']).sem()['Salary_Index']\n",
    "\n",
    "# Created a DF\n",
    "stats_summary=pd.DataFrame({\"Mean Salary Index\": average,\n",
    "                           \"Median Salary Index\": median,\n",
    "                           \"Salary Index Variance\":variance,\n",
    "                           \"Salary Index Std. Dev.\":standard_deviation,\n",
    "                           \"Salary Index Std. Err.\":sem\n",
    "                          })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cleaned['Salary_Index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DF by industry type, salary, and job title \n",
    "industry_df=df_cleaned[['Job_Title',\\\n",
    "                       'Queried_Salary',\\\n",
    "                       'Consulting and Business Services',\\\n",
    "                       'Internet and Software',\\\n",
    "                       'Banks and Financial Services',\\\n",
    "                       'Health Care',\\\n",
    "                       'Insurance',\\\n",
    "                       'Other_industries']]\n",
    "industry_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by highest pay \n",
    "high_pay_industry=industry_df[industry_df['Queried_Salary']== '>160000']\n",
    "high_pay_industry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total nums of industry for each job title\n",
    "#consulting\n",
    "consulting_tot=high_pay_industry['Consulting and Business Services'].sum(axis = 0, skipna = True)\n",
    "\n",
    "#internet & software\n",
    "internet_tot=high_pay_industry['Internet and Software'].sum(axis = 0, skipna = True)\n",
    "\n",
    "#banks\n",
    "banks_tot=high_pay_industry['Banks and Financial Services'].sum(axis = 0, skipna = True)\n",
    "\n",
    "#health\n",
    "health_tot=high_pay_industry['Health Care'].sum(axis = 0, skipna = True)\n",
    "\n",
    "#insurance\n",
    "insurance_tot=high_pay_industry['Insurance'].sum(axis = 0, skipna = True)\n",
    "\n",
    "#other industry\n",
    "other_tot=high_pay_industry['Other_industries'].sum(axis = 0, skipna = True)\n",
    "\n",
    "print(f'total consulting = {consulting_tot}')\n",
    "print(f'total for internet= {internet_tot}')\n",
    "print(f'total for banks and finance= {banks_tot}')\n",
    "print(f'total for health= {health_tot}')\n",
    "print(f'total for insurance= {insurance_tot}')\n",
    "print(f'total for other industries= {other_tot}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_industry_count=consulting_tot+internet_tot+banks_tot+health_tot+insurance_tot+other_tot\n",
    "total_industry_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage by industry\n",
    "consult_percent=\"{:.0%}\".format(consulting_tot/total_industry_count)\n",
    "\n",
    "internet_percent=\"{:.0%}\".format(internet_tot/total_industry_count)\n",
    "\n",
    "banks_percent=\"{:.0%}\".format(banks_tot/total_industry_count)\n",
    "\n",
    "health_percent=\"{:.0%}\".format(health_tot/total_industry_count)\n",
    "\n",
    "insurance_percent=\"{:.0%}\".format(insurance_tot/total_industry_count)\n",
    "\n",
    "other_percent=\"{:.0%}\".format(other_tot/total_industry_count)\n",
    "\n",
    "\n",
    "# percentage_summary=pd.DataFrame({\"Count of Consulting Industry\": consulting_tot,\n",
    "#                            \"Count of Internet Industry\":internet_tot,\n",
    "#                            \"Count of Banks\":banks_tot,\n",
    "#                            \"Count of Health\":health_tot,\n",
    "#                            \"Count of Insurance\":insurance_tot,\n",
    "#                             \"Count of Other\":other_tot },index=[0])\n",
    "# percentage_summary\n",
    "data={'Industries':[\"Consulting and Business Services\",\\\n",
    "                    \"Internet and Software\",\\\n",
    "                    \"Banks and Financial Services\",\\\n",
    "                    \"Health Care\",\\\n",
    "                    \"Insurance\",\"\\\n",
    "                    Other Industries\"],'Totals':[consulting_tot,internet_tot,banks_tot,health_tot,insurance_tot,other_tot]}\n",
    "summary_df = pd.DataFrame(data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=summary_df.set_index('Industries')\n",
    "subset\n",
    "# plot = summary_df.plot.pie(subplots=True, figsize=(11, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.plot.pie(y='Totals',figsize=(6, 6),autopct='%1.1f%%', startangle=90,pctdistance=1.1, labeldistance=1.2)\n",
    "ax=plt.subplot()\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(2.5,1.00))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_no_cities=df[\"Location\"].unique()\n",
    "# total_no_cities\n",
    "city_index = (df_cleaned[ df_cleaned['Location'] == 'REMOTE' ].index)\n",
    "df_cleaned.drop(city_index, inplace=True)\n",
    "\n",
    "city_index = (df_cleaned[ df_cleaned['Location'] == 'USA' ].index)\n",
    "df_cleaned.drop(city_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_index2 = df_cleaned[ df_cleaned['Location'] == 'nan' ].index\n",
    "df_cleaned.drop(city_index2, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.dropna(subset=['Location'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobs By Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cleaned.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find company with most job listings\n",
    "num_company=df_cleaned['Company'].nunique()\n",
    "print(f'There are a total of {num_company} job openings')\n",
    "\n",
    "most_job_openings= df_cleaned.groupby(['Company'])['Job_Type'].count()\n",
    "top_company=pd.DataFrame(most_job_openings.nlargest(20))\n",
    "\n",
    "\n",
    "plot=top_company.plot(kind='bar', align=\"center\",figsize = (15,7))\n",
    "plt.title(\"Companies with Highest Job Listings\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_city=df_cleaned.groupby(['Location'])['Company'].count()\n",
    "state_df=pd.DataFrame(job_count_city.nlargest(50))\n",
    "state_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=state_df.plot(kind='bar', align=\"center\",figsize = (15,7))\n",
    "plt.title('Job openings by State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df=pd.DataFrame(df_cleaned.loc[:,['Location',\\\n",
    "                                    'Consulting and Business Services',\\\n",
    "                                    'Internet and Software',\\\n",
    "                                    'Banks and Financial Services',\\\n",
    "                                    'Health Care',\\\n",
    "                                   'Insurance',\\\n",
    "                                    'Company']])\n",
    "industry_df.dropna()\n",
    "\n",
    "industry_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df[\"Lat\"] = \"\"\n",
    "state_df[\"Lng\"] = \"\"\n",
    "state_df.groupby(['Location'])\n",
    "state_bylocation=pd.DataFrame(state_df)\n",
    "state_bylocation.reset_index(inplace=True)\n",
    "state_bylocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": gkey}\n",
    "max_rows=200\n",
    "# Loop through the location and run a lat/long search for each city\n",
    "for index, row in state_bylocation.iterrows():\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "    state = row['Location']\n",
    "    \n",
    "\n",
    "    # update address key value\n",
    "    params['address'] = f\"{state}\"\n",
    "\n",
    "#     # make request\n",
    "    state_lat_lng = requests.get(base_url, params=params)\n",
    "\n",
    "#     # print the cities_lat_lng url, avoid doing for public github repos in order to avoid exposing key\n",
    "#     print(state_lat_lng.url)\n",
    "    \n",
    "# #     # convert to json\n",
    "    state_lat_lng = state_lat_lng.json()\n",
    "#     print(state_lat_lng['results'][0]['geometry']['location'])\n",
    "#     time.sleep(1.00)\n",
    "\n",
    "    state_bylocation.loc[index, \"Lat\"] = state_lat_lng[\"results\"][0]['geometry'][\"location\"][\"lat\"]\n",
    "    state_bylocation.loc[index,'Lng']= state_lat_lng[\"results\"][0]['geometry'][\"location\"][\"lng\"]\n",
    "    if index >max_rows and max_rows>0:\n",
    "        break\n",
    "state_bylocation.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "locations=state_bylocation[['Lat','Lng']]\n",
    "fig = gmaps.figure()\n",
    "\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights=state_bylocation['Company'], \n",
    "                                 dissipating=False, max_intensity=100,\n",
    "                                 point_radius = 1)\n",
    "fig.add_layer(heat_layer)\n",
    "state_template=\"\"\"<dl><dd>{Location}</dd></dl>\"\"\"\n",
    "state_info=[state_template.format(**row) for index,row in state_bylocation.iterrows()]\n",
    "# print(state_info)\n",
    "marker_layer=gmaps.marker_layer(locations,info_box_content= state_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = industry_df.groupby(['Location'])['Company']\n",
    "\n",
    "params = {\"address\": state, \"key\": gkey}\n",
    "\n",
    "# Build URL using the Google Maps API\n",
    "base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "\n",
    "# Run request\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# print the response URL, avoid doing for public GitHub repos in order to avoid exposing key\n",
    "# print(response.url)\n",
    "\n",
    "# Convert to JSON\n",
    "response = response.json()\n",
    "\n",
    "# Extract lat/lng\n",
    "lat = response[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "lng = response[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "# Print results\n",
    "print('Hi')\n",
    "print(f\"{target_state}: {lat}, {lng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_count=df_cleaned['Location'].value_counts()\n",
    "# city_name=df_cleaned['Location']\n",
    "# city_df=pd.DataFrame({'Location':city_count,'Total Jobs': city_count})\n",
    "# city=len(df_cleaned['Location'])\n",
    "# city_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ratio=df_cleaned['Location'].value_counts(normalize=True)*100\n",
    "statedata_df=pd.DataFrame(state_ratio)\n",
    "statedata_df.reset_index(level=0, inplace=True)\n",
    "clean_state=statedata_df.rename(columns={\"index\": \"Location\", \"Location\": \"Total Jobs %\"})\n",
    "\n",
    "clean_state.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_plot=statedata_df.plot.bar(x='index', y='Location',rot=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_state=statedata_df.rename(columns={\"index\": \"Location\", \"Location\": \"Total Jobs\"})\n",
    "# city_percent=clean_city.style.format({'Total Jobs': \"{:.2%}\".format})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
